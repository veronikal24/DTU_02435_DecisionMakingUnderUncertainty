{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Markov Decision Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average performance of dummy policy: -845.5668737655192\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import WindProcess\n",
    "import PriceProcess\n",
    "from data import get_fixed_data\n",
    "\n",
    "class HydrogenMDP:\n",
    "    def __init__(self, policy, episodes=10):\n",
    "        self.data = get_fixed_data()\n",
    "        self.T = self.data['num_timeslots']\n",
    "        self.episodes = episodes\n",
    "        self.policy = policy  # Policy function: (s, t) -> action\n",
    "\n",
    "    def simulate(self):\n",
    "        total_rewards = []\n",
    "        for _ in range(self.episodes):\n",
    "            total_reward = self.run_episode()\n",
    "            total_rewards.append(total_reward)\n",
    "        return np.mean(total_rewards)\n",
    "\n",
    "    def run_episode(self):\n",
    "        s_h = 0  # Initial hydrogen storage\n",
    "        total_reward = 0\n",
    "        wind_series = np.random.normal(self.data['target_mean_wind'], 1, self.T)\n",
    "        price_series = np.random.normal(self.data['mean_price'], 5, self.T)\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            state = (s_h, wind_series[t], price_series[t])\n",
    "            action = self.policy(state, t)\n",
    "            \n",
    "            x_t, p2h_t, h2p_t, g_t = action\n",
    "            \n",
    "            s_h = min(max(s_h + self.data['conversion_p2h'] * p2h_t - h2p_t / self.data['conversion_h2p'], 0), self.data['hydrogen_capacity'])\n",
    "            cost = price_series[t] * g_t + self.data['electrolyzer_cost'] * x_t\n",
    "            total_reward -= cost  # Negative cost as reward\n",
    "        \n",
    "        return total_reward\n",
    "\n",
    "# Dummy policy: Never use electrolyzer\n",
    "def dummy_policy(state, t):\n",
    "    s_h, p_wind, lambda_grid = state\n",
    "    return (0, 0, 0, max(0, get_fixed_data()['demand_schedule'][t] - p_wind))\n",
    "\n",
    "# Run simulation\n",
    "mdp = HydrogenMDP(dummy_policy, episodes=100)\n",
    "average_performance = mdp.simulate()\n",
    "print(\"Average performance of dummy policy:\", average_performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
